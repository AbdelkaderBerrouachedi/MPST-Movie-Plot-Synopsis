{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14828 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'F:\\mpst_full_data.csv', delimiter=',')\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id                                          title  \\\n",
       "0  tt0057603                        I tre volti della paura   \n",
       "1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2  tt0033045                     The Shop Around the Corner   \n",
       "3  tt0113862                             Mr. Holland's Opus   \n",
       "4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb  \n",
       "1                                           violence  train            imdb  \n",
       "2                                           romantic   test            imdb  \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb  \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imdb_id', 'title', 'plot_synopsis', 'tags', 'synopsis_source'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined']=df['title']+\". \"+ df['plot_synopsis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Sequential()) == Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "# import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdd(x):\n",
    "    a=x.split()\n",
    "    return len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['combined'] = df['combined'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6119"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['combined'].apply(gdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict.keys()\n",
    "x=df['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags=label_dict['idx2word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (14828, 6119)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['combined'].values)\n",
    "X = pad_sequences(X, maxlen=6119)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=pd.get_dummies(df['tags'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (14828, 24)\n"
     ]
    }
   ],
   "source": [
    "y = tokenizer.texts_to_sequences(df['tags'].values)\n",
    "y = pad_sequences(y, maxlen=24)\n",
    "print('Shape of data tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=6119, lower=True)\n",
    "tokenizer.fit_on_texts(df.combined)\n",
    "sequences = tokenizer.texts_to_sequences(df.combined)\n",
    "x = pad_sequences(sequences, maxlen=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df.tags)\n",
    "y = multilabel_binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(label_dict['idx2word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, ..., 1464,  840, 5480])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# ths is correct only\n",
    "# but once you have it done, we need to check the contents of the multilabel_y\n",
    "multilabel_y = vectorizer.fit_transform(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multilabel_y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)\n",
    "# x_train=x[:1000]\n",
    "# x_test=x[1000:]\n",
    "# y_train=y[:1000]\n",
    "# y_test=y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0])\n",
    "# n_classes = _count_classes(y_train)\n",
    "n_classes=147\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10675 samples, validate on 1187 samples\n",
      "Epoch 1/5\n",
      "10675/10675 [==============================] - 59s 6ms/step - loss: 0.1489 - categorical_accuracy: 0.1457 - val_loss: 0.1309 - val_categorical_accuracy: 0.1862\n",
      "Epoch 2/5\n",
      "10675/10675 [==============================] - 58s 5ms/step - loss: 0.1308 - categorical_accuracy: 0.1799 - val_loss: 0.1284 - val_categorical_accuracy: 0.1896\n",
      "Epoch 3/5\n",
      "10675/10675 [==============================] - 59s 5ms/step - loss: 0.1278 - categorical_accuracy: 0.1883 - val_loss: 0.1268 - val_categorical_accuracy: 0.1752\n",
      "Epoch 4/5\n",
      "10675/10675 [==============================] - 58s 5ms/step - loss: 0.1259 - categorical_accuracy: 0.1909 - val_loss: 0.1282 - val_categorical_accuracy: 0.1887\n",
      "Epoch 5/5\n",
      "10675/10675 [==============================] - 57s 5ms/step - loss: 0.1242 - categorical_accuracy: 0.1904 - val_loss: 0.1289 - val_categorical_accuracy: 0.1946\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Embedding(6119, 71, input_length=1200))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(82, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(0.015), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-simple.hdf5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight='balanced',\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 1200, 71)          434449    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1200, 71)          0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1200, 256)         18432     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1200, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1200, 128)         32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1200, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1200, 8)           1032      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 82)                738       \n",
      "=================================================================\n",
      "Total params: 487,547\n",
      "Trainable params: 487,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Embedding(6119, 71, input_length=1200))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.60))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(82, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(0.015), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-simple.hdf5', save_best_only=True)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10675 samples, validate on 1187 samples\n",
      "Epoch 1/5\n",
      " 2880/10675 [=======>......................] - ETA: 2:55 - loss: 0.1735 - categorical_accuracy: 0.1187"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight='balanced',\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1200, 71)          434449    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1200, 71)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1198, 300)         64200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 82)                24682     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 82)                0         \n",
      "=================================================================\n",
      "Total params: 523,331\n",
      "Trainable params: 523,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(6119, 71, input_length=1200))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(82))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10675 samples, validate on 1187 samples\n",
      "Epoch 1/5\n",
      "10675/10675 [==============================] - 332s 31ms/step - loss: 0.1692 - categorical_accuracy: 0.1334 - val_loss: 0.1324 - val_categorical_accuracy: 0.1634\n",
      "Epoch 2/5\n",
      "10675/10675 [==============================] - 249s 23ms/step - loss: 0.1310 - categorical_accuracy: 0.1647 - val_loss: 0.1298 - val_categorical_accuracy: 0.1778\n",
      "Epoch 3/5\n",
      "10675/10675 [==============================] - 249s 23ms/step - loss: 0.1270 - categorical_accuracy: 0.1834 - val_loss: 0.1254 - val_categorical_accuracy: 0.1660\n",
      "Epoch 4/5\n",
      "10675/10675 [==============================] - 249s 23ms/step - loss: 0.1226 - categorical_accuracy: 0.1975 - val_loss: 0.1250 - val_categorical_accuracy: 0.1702\n",
      "Epoch 5/5\n",
      "10675/10675 [==============================] - 252s 24ms/step - loss: 0.1174 - categorical_accuracy: 0.2128 - val_loss: 0.1244 - val_categorical_accuracy: 0.1752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight='balanced',\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_length = 300\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(6119, 71, input_length=1200))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(300, 3, activation='relu'))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "# model.add(Conv1D(200, 3, activation='relu'))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "# model.add(Dense(82))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(6119, output_dim=71))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(82, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9489 samples, validate on 2373 samples\n",
      "Epoch 1/12\n",
      "9489/9489 [==============================] - 715s 75ms/step - loss: 0.1572 - acc: 0.9547 - val_loss: 0.1361 - val_acc: 0.9602\n",
      "Epoch 2/12\n",
      "9489/9489 [==============================] - 734s 77ms/step - loss: 0.1392 - acc: 0.9599 - val_loss: 0.1360 - val_acc: 0.9602\n",
      "Epoch 3/12\n",
      "9489/9489 [==============================] - 729s 77ms/step - loss: 0.1374 - acc: 0.9600 - val_loss: 0.1360 - val_acc: 0.9602\n",
      "Epoch 4/12\n",
      "9489/9489 [==============================] - 579s 61ms/step - loss: 0.1353 - acc: 0.9601 - val_loss: 0.1346 - val_acc: 0.9604\n",
      "Epoch 5/12\n",
      "5536/9489 [================>.............] - ETA: 3:00 - loss: 0.1312 - acc: 0.9607"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "model.fit(x_train, y_train,\n",
    "          class_weight='balanced',\n",
    "          epochs=12,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # Configuring the parameters\n",
    "# model.add(LSTM(6119, input_shape=(timesteps, input_dim)))\n",
    "# # Adding a dropout layer\n",
    "# model.add(Dropout(0.5))\n",
    "# # Adding a dense output layer with sigmoid activation\n",
    "# model.add(Dense(n_classes, activation='sigmoid'))\n",
    "# model.summary()\n",
    "# pred=[]\n",
    "# x= model.predict(y_test)\n",
    "# for i in x:\n",
    "#     pred.append(i[:])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(y_test[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(6119, output_dim=71))\n",
    "# # model.add(LSTM(300))\n",
    "# model.add(LSTM(256, return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(128))\n",
    "\n",
    "# # model.add(LSTM(150))\n",
    "\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(82, activation='sigmoid'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           class_weight='balanced',\n",
    "#           epochs=12,\n",
    "#           batch_size=32,\n",
    "#           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
